{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='your module name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f0/6j6j3w814n53skbt2s4d8p5m0000gn/T/ipykernel_61938/1208280586.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"text\"].iloc[i] = ' '.join(words)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../nlpia/topic_analysis/smalldata_washed.csv')\n",
    "rumor = data['rumor'].to_list()\n",
    "reverse = data['reverse'].to_list()\n",
    "rumor_class = len(rumor)*[1]\n",
    "reverse_class = len(reverse)*[0]\n",
    "data = rumor + reverse\n",
    "data_class = rumor_class + reverse_class\n",
    "#后续添加数据要放在raw目录下，使用.xlsx格式将后续标注的数据加入data\n",
    "raw_data_list = os.listdir('../nlpia/topic_analysis/raw')\n",
    "data_list = []\n",
    "good_name = re.compile(r'^(?!(\\~\\$)).*(.xlsx)')\n",
    "for i in raw_data_list:\n",
    "    if good_name.match(i):\n",
    "    #    data_list.append(i)\n",
    "        temp = pd.read_excel('../nlpia/topic_analysis/raw/'+i)\n",
    "        temp.fillna('',inplace=True)\n",
    "        temp_rumor = [x.strip() for x in  temp['punc_rumor'].to_list()  if x.strip()!='']\n",
    "        temp_reverse = [x.strip() for x in  temp['punc_truth'].to_list()  if x.strip()!='']\n",
    "        temp_rumor_class = len(temp_rumor)*[1]\n",
    "        temp_reverse_class = len(temp_reverse)*[0]\n",
    "        temp_data = temp_rumor + temp_reverse\n",
    "        temp_data_class = temp_rumor_class + temp_reverse_class\n",
    "        for i in range( len(temp_data)):\n",
    "            temp_data[i]=re.sub(r'[\\,\\'\\ ]|(\\n)','',temp_data[i])\n",
    "    data = data + temp_data\n",
    "    data_class = data_class + temp_data_class\n",
    "with open('../nlpia/topic_analysis/data.txt','w') as f:\n",
    "    for i in range(len(data)):\n",
    "        f.write(data[i]+'\\t'+str(data_class[i])+'\\n')\n",
    "        data_list =list( zip(data, data_class))\n",
    "random.shuffle(data_list)\n",
    "data, data_class = zip(*data_list)\n",
    "index = ['rumor{}{}'.format(i, '!' * j) for (i, j) in zip(range(len(data)), data_class)]\n",
    "df = pd .DataFrame(data=zip(data_class,data), columns=[\"rumor\",\"text\"], index=index)\n",
    "\n",
    "# 去除停用词\n",
    "with open ('../nlpia/topic_analysis/hit_stopwords.txt', 'r', encoding='utf-8') as f:\n",
    "    stopwords = f.read().splitlines()\n",
    "\n",
    "# jieba分词\n",
    "import jieba\n",
    "for i in range(len(df)):\n",
    "    words = jieba.cut(df[\"text\"].iloc[i],cut_all=False)\n",
    "    words = [word for word in words if word not in stopwords]\n",
    "    df[\"text\"].iloc[i] = ' '.join(words) \n",
    "\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import casual_tokenize\n",
    "np.random.seed(42)\n",
    "\n",
    "counter = CountVectorizer(tokenizer=casual_tokenize)\n",
    "bow_docs = pd.DataFrame(counter.fit_transform(raw_documents=df.text)\n",
    "                        .toarray(), index=index)\n",
    "column_nums, terms = zip(*sorted(zip(counter.vocabulary_.values(),\n",
    "                                     counter.vocabulary_.keys())))\n",
    "bow_docs.columns = terms\n",
    "\n",
    "try:\n",
    "    print('rumor0:'+df.loc['rumor0'].text)\n",
    "    print(bow_docs.loc['rumor0'][bow_docs.loc['rumor0'] > 0].head())\n",
    "except KeyError:\n",
    "    print('rumor0!:'+df.loc['rumor0!'].text)\n",
    "    print(bow_docs.loc['rumor0!'][bow_docs.loc['rumor0!'] > 0].head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 对比TF-IDF向量的分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stevenyu/opt/anaconda3/envs/d2l/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import casual_tokenize\n",
    "tfidf = TfidfVectorizer(tokenizer=casual_tokenize,)\n",
    "tfidf_docs =tfidf.fit_transform(raw_documents=df.text).toarray()\n",
    "tfidf_docs = tfidf_docs - tfidf_docs.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "过采样前训练集中类别0的数量： 1505\n",
      "过采样前训练集中类别1的数量： 722\n",
      "过采样后训练集中类别0的数量： 1505\n",
      "过采样后训练集中类别1的数量： 1505\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(tfidf_docs,df.rumor,test_size=0.2,random_state=42)\n",
    "smote = SMOTE(random_state=42)\n",
    "# 进行过采样\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "print(\"过采样前训练集中类别0的数量：\", sum(y_train==0))\n",
    "print(\"过采样前训练集中类别1的数量：\", sum(y_train==1))\n",
    "\n",
    "print(\"过采样后训练集中类别0的数量：\", sum(y_train_res==0))\n",
    "print(\"过采样后训练集中类别1的数量：\", sum(y_train_res==1))\n",
    "lda = LDA()\n",
    "lda = lda.fit(X_train_res, y_train_res)\n",
    "df['tfidf_rumor'] = lda.predict(tfidf_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.801"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(float(lda.score(X_test, y_test)), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   non-rumor     0.8947    0.7896    0.8389       366\n",
      "       rumor     0.6709    0.8220    0.7388       191\n",
      "\n",
      "    accuracy                         0.8007       557\n",
      "   macro avg     0.7828    0.8058    0.7889       557\n",
      "weighted avg     0.8180    0.8007    0.8046       557\n",
      "\n",
      "[[289  77]\n",
      " [ 34 157]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn import metrics\n",
    "import time\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "y_true = df.loc[y_test.index].rumor\n",
    "y_pred = df.loc[y_test.index].tfidf_rumor\n",
    "loss_total = 0\n",
    "acc = metrics.accuracy_score(y_true, y_pred)\n",
    "report = metrics.classification_report(y_true, y_pred, target_names=[\"non-rumor\",\"rumor\"], digits=4)\n",
    "confusion = metrics.confusion_matrix(y_true, y_pred)\n",
    "print(report)\n",
    "print(confusion)\n",
    "with open(\"../Chinese-Text-Classification-Pytorch/report/\"+'tfidf'+'.txt', 'w', encoding='utf-8') as f:\n",
    "    print(report,file=f)\n",
    "\n",
    "with open(\"../Chinese-Text-Classification-Pytorch/report_matrix/\"+'tfidf'+'_matrix'+'.txt', 'w', encoding='utf-8') as f:\n",
    "    print(confusion,file=f)\n",
    "np.savez(\"../Chinese-Text-Classification-Pytorch/report_matrix/\"+'tfidf'+'_matrix'+'.npz', matrix= confusion)    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 隐形狄利克雷分布原理\n",
    "- 设想一台自动生成文档的机器，只有两个选项来控制生成文档的两个属性\n",
    "    - 生成文档的词的数量（泊松分布）\n",
    "    - 文档中混合的主题的数量（狄利克雷分布）\n",
    "- 除此之外，最关键的问题在于确定一个主题-词项矩阵，该矩阵表示了每个词对主题的贡献权重。一但能够确定这个矩阵，机器就可以在选择好的主题上反复迭代选择词，直到生成一篇足够长度的文档。\n",
    "- 回到对现有文档估计主题的问题上来，LDiA可以用于关于词和主题的参数，Blei和Ng通过分析语料库中文档的统计数据确定两个参数\n",
    "    - 第一个参数可以通过计算语料库的平均词（n-gram）数量、\n",
    "    - 第二个参数更棘手，必须先猜测有几个主题数再为主题分配语词，最后优化目标函数\n",
    "-  “LSA试图将原本分散的东西分散开，LDiA试图将原本接近的东西接近在一起”\n",
    "LDiA使用100个主题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 9200)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation as LDiA\n",
    "ldia100 = LDiA(n_components=100, learning_method='batch')\n",
    "ldia100 = ldia100.fit(bow_docs)\n",
    "ldia100.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic0</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>topic4</th>\n",
       "      <th>topic5</th>\n",
       "      <th>topic6</th>\n",
       "      <th>topic7</th>\n",
       "      <th>topic8</th>\n",
       "      <th>topic9</th>\n",
       "      <th>...</th>\n",
       "      <th>topic90</th>\n",
       "      <th>topic91</th>\n",
       "      <th>topic92</th>\n",
       "      <th>topic93</th>\n",
       "      <th>topic94</th>\n",
       "      <th>topic95</th>\n",
       "      <th>topic96</th>\n",
       "      <th>topic97</th>\n",
       "      <th>topic98</th>\n",
       "      <th>topic99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rumor0!</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor4!</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         topic0  topic1  topic2  topic3  topic4  topic5  topic6  topic7  \\\n",
       "rumor0!     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "rumor1      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "rumor2      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "rumor3      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "rumor4!     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "         topic8  topic9  ...  topic90  topic91  topic92  topic93  topic94  \\\n",
       "rumor0!     0.0     0.0  ...      0.0      0.0      0.0      0.0      0.0   \n",
       "rumor1      0.0     0.0  ...      0.0      0.0      0.0      0.0      0.0   \n",
       "rumor2      0.0     0.0  ...      0.0      0.0      0.0      0.0      0.0   \n",
       "rumor3      0.0     0.0  ...      0.0      0.0      0.0      0.0      0.0   \n",
       "rumor4!     0.0     0.0  ...      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "         topic95  topic96  topic97  topic98  topic99  \n",
       "rumor0!      0.0      0.0      0.0      0.0      0.0  \n",
       "rumor1       0.0      0.0      0.0      0.0      0.0  \n",
       "rumor2       0.0      0.0      0.0      0.0      0.0  \n",
       "rumor3       0.0      0.0      0.0      0.0      0.0  \n",
       "rumor4!      0.0      0.0      0.0      0.0      0.0  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldia100_topic_vectors = ldia100.transform(bow_docs)\n",
    "columns100 = ['topic{}'.format(i) for i in range(ldia100.components_.shape[0])]\n",
    "ldia100_topic_vectors = pd.DataFrame(ldia100_topic_vectors,index=index, columns=columns100)\n",
    "ldia100_topic_vectors.round(2).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "过采样前训练集中类别0的数量： 1505\n",
      "过采样前训练集中类别1的数量： 722\n",
      "过采样后训练集中类别0的数量： 1505\n",
      "过采样后训练集中类别1的数量： 1505\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.56"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(ldia100_topic_vectors,df.rumor,test_size=0.2,random_state=42)\n",
    "smote = SMOTE(random_state=42)\n",
    "# 进行过采样\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "print(\"过采样前训练集中类别0的数量：\", sum(y_train==0))\n",
    "print(\"过采样前训练集中类别1的数量：\", sum(y_train==1))\n",
    "\n",
    "print(\"过采样后训练集中类别0的数量：\", sum(y_train_res==0))\n",
    "print(\"过采样后训练集中类别1的数量：\", sum(y_train_res==1))\n",
    "lda = LDA()\n",
    "lda = lda.fit(X_train_res, y_train_res)\n",
    "df['ldia100_rumor'] = lda.predict(ldia100_topic_vectors)\n",
    "round(float(lda.score(X_test, y_test)), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   non-rumor     0.7051    0.5683    0.6293       366\n",
      "       rumor     0.3969    0.5445    0.4592       191\n",
      "\n",
      "    accuracy                         0.5601       557\n",
      "   macro avg     0.5510    0.5564    0.5443       557\n",
      "weighted avg     0.5994    0.5601    0.5710       557\n",
      "\n",
      "[[208 158]\n",
      " [ 87 104]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn import metrics\n",
    "import time\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "y_true = df.loc[y_test.index].rumor\n",
    "y_pred = df.loc[y_test.index].ldia100_rumor\n",
    "loss_total = 0\n",
    "acc = metrics.accuracy_score(y_true, y_pred)\n",
    "report = metrics.classification_report(y_true, y_pred, target_names=[\"non-rumor\",\"rumor\"], digits=4)\n",
    "confusion = metrics.confusion_matrix(y_true, y_pred)\n",
    "print(report)\n",
    "print(confusion)\n",
    "with open(\"../Chinese-Text-Classification-Pytorch/report/\"+\"ldia\"+'.txt', 'w', encoding='utf-8') as f:\n",
    "    print(report,file=f)\n",
    "with open(\"../Chinese-Text-Classification-Pytorch/report_matrix/\"+'ldia'+'_matrix'+'.txt', 'w', encoding='utf-8') as f:\n",
    "    print(confusion,file=f)\n",
    "np.savez(\"../Chinese-Text-Classification-Pytorch/report_matrix/\"+'ldia'+'_matrix'+'.npz', matrix= confusion)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "k=min(len(tfidf.vocabulary_),len(df))\n",
    "k=100\n",
    "pca = PCA(n_components=k)\n",
    "pca_docs = pca.fit_transform(tfidf_docs)\n",
    "base = sum(pca.singular_values_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = pca.singular_values_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic0</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>topic4</th>\n",
       "      <th>topic5</th>\n",
       "      <th>topic6</th>\n",
       "      <th>topic7</th>\n",
       "      <th>topic8</th>\n",
       "      <th>topic9</th>\n",
       "      <th>...</th>\n",
       "      <th>topic90</th>\n",
       "      <th>topic91</th>\n",
       "      <th>topic92</th>\n",
       "      <th>topic93</th>\n",
       "      <th>topic94</th>\n",
       "      <th>topic95</th>\n",
       "      <th>topic96</th>\n",
       "      <th>topic97</th>\n",
       "      <th>topic98</th>\n",
       "      <th>topic99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rumor0!</th>\n",
       "      <td>0.024</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor1</th>\n",
       "      <td>-0.031</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.037</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.029</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.087</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>-0.079</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>0.042</td>\n",
       "      <td>-0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor2</th>\n",
       "      <td>0.092</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.031</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.026</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>0.022</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor3</th>\n",
       "      <td>0.033</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.053</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.097</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.021</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.034</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.080</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>-0.093</td>\n",
       "      <td>-0.095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor4!</th>\n",
       "      <td>0.024</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>0.023</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.016</td>\n",
       "      <td>-0.054</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>0.112</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>-0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor5</th>\n",
       "      <td>0.011</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>0.045</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>0.026</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         topic0  topic1  topic2  topic3  topic4  topic5  topic6  topic7  \\\n",
       "rumor0!   0.024  -0.036  -0.030   0.014  -0.036  -0.048  -0.001   0.002   \n",
       "rumor1   -0.031  -0.052   0.026   0.037  -0.004  -0.023  -0.040  -0.047   \n",
       "rumor2    0.092   0.110   0.104   0.010   0.048   0.031  -0.036  -0.020   \n",
       "rumor3    0.033  -0.028  -0.053   0.018   0.097  -0.103   0.039   0.072   \n",
       "rumor4!   0.024  -0.040  -0.038   0.023  -0.037  -0.058   0.001   0.016   \n",
       "rumor5    0.011  -0.023  -0.031   0.045  -0.026  -0.027  -0.040   0.026   \n",
       "\n",
       "         topic8  topic9  ...  topic90  topic91  topic92  topic93  topic94  \\\n",
       "rumor0!  -0.031  -0.000  ...   -0.001   -0.013   -0.008    0.013    0.008   \n",
       "rumor1    0.023   0.029  ...   -0.023    0.087   -0.044   -0.079   -0.013   \n",
       "rumor2    0.003   0.035  ...    0.028    0.026   -0.058    0.022   -0.013   \n",
       "rumor3    0.021  -0.017  ...   -0.025    0.010    0.034   -0.020   -0.037   \n",
       "rumor4!  -0.054  -0.005  ...   -0.000   -0.025   -0.068    0.006   -0.001   \n",
       "rumor5   -0.010  -0.047  ...    0.081    0.018    0.014    0.044   -0.004   \n",
       "\n",
       "         topic95  topic96  topic97  topic98  topic99  \n",
       "rumor0!   -0.001    0.014   -0.010    0.000   -0.014  \n",
       "rumor1    -0.052   -0.023   -0.026    0.042   -0.020  \n",
       "rumor2     0.012    0.032    0.025    0.040    0.042  \n",
       "rumor3     0.054    0.080   -0.020   -0.093   -0.095  \n",
       "rumor4!    0.056   -0.018    0.112   -0.058   -0.022  \n",
       "rumor5    -0.026    0.075    0.033    0.017   -0.015  \n",
       "\n",
       "[6 rows x 100 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=k)\n",
    "pca_docs = pca.fit_transform(tfidf_docs)\n",
    "pca_topic_vectors = pca.transform(tfidf_docs)\n",
    "columns = ['topic{}'.format(i) for i in range(pca_docs.shape[1])]\n",
    "pca_topic_vectors = pd.DataFrame(pca_topic_vectors, columns=columns, index=index)\n",
    "pca_topic_vectors.round(3).head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.vocabulary_\n",
    "#根据词项的频率对词汇表进行排序\n",
    "#当对某个不按照最左边元素排序的序列解压并在排序后重新压缩时，可以使用zip(*sorted(zip(...)))\n",
    "column_nums , terms = zip(*sorted(zip(tfidf.vocabulary_.values(), tfidf.vocabulary_.keys())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>%</th>\n",
       "      <th>.</th>\n",
       "      <th>0</th>\n",
       "      <th>0t</th>\n",
       "      <th>...</th>\n",
       "      <th>鼻炎</th>\n",
       "      <th>鼻翼</th>\n",
       "      <th>龋齿</th>\n",
       "      <th>龙葵</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>topic0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic1</th>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic2</th>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 9200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            %      .    0     0t  ...     鼻炎     鼻翼     龋齿     龙葵\n",
       "topic0  0.001 -0.001  0.0 -0.000  ... -0.000  0.000  0.001 -0.001\n",
       "topic1 -0.001  0.000 -0.0 -0.001  ... -0.002 -0.000 -0.001 -0.002\n",
       "topic2 -0.001  0.001 -0.0 -0.001  ... -0.002 -0.001 -0.001  0.000\n",
       "topic3  0.000  0.004  0.0  0.001  ... -0.002  0.001  0.001 -0.002\n",
       "\n",
       "[4 rows x 9200 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = pd.DataFrame(pca.components_, columns=terms,\n",
    "                       index = ['topic{}'.format(i) for i in range(pca.components_.shape[0])])\n",
    "pd.options.display.max_columns = 8\n",
    "weights.head(4).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic0</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>...</th>\n",
       "      <th>topic96</th>\n",
       "      <th>topic97</th>\n",
       "      <th>topic98</th>\n",
       "      <th>topic99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rumor0!</th>\n",
       "      <td>0.024</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>0.014</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor1</th>\n",
       "      <td>-0.031</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.037</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor2</th>\n",
       "      <td>0.092</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor3</th>\n",
       "      <td>0.033</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.053</td>\n",
       "      <td>0.018</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>0.026</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>0.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor4!</th>\n",
       "      <td>0.024</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>0.023</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor5</th>\n",
       "      <td>0.011</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>0.045</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         topic0  topic1  topic2  topic3  ...  topic96  topic97  topic98  \\\n",
       "rumor0!   0.024  -0.036  -0.030   0.014  ...   -0.005   -0.008    0.019   \n",
       "rumor1   -0.031  -0.052   0.026   0.037  ...   -0.030   -0.026    0.041   \n",
       "rumor2    0.092   0.110   0.104   0.010  ...    0.004   -0.028   -0.001   \n",
       "rumor3    0.033  -0.028  -0.053   0.018  ...   -0.036    0.026   -0.047   \n",
       "rumor4!   0.024  -0.040  -0.038   0.023  ...   -0.087   -0.004   -0.072   \n",
       "rumor5    0.011  -0.023  -0.031   0.045  ...    0.009    0.049    0.023   \n",
       "\n",
       "         topic99  \n",
       "rumor0!    0.026  \n",
       "rumor1    -0.047  \n",
       "rumor2     0.018  \n",
       "rumor3     0.051  \n",
       "rumor4!    0.021  \n",
       "rumor5     0.051  \n",
       "\n",
       "[6 rows x 100 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=k,n_iter=100)\n",
    "svd_topic_vectors = svd.fit_transform(tfidf_docs)\n",
    "svd_topic_vectors = pd.DataFrame(svd_topic_vectors, columns=columns, index=index)\n",
    "svd_topic_vectors.round(3).head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "过采样前训练集中类别0的数量： 1505\n",
      "过采样前训练集中类别1的数量： 722\n",
      "过采样后训练集中类别0的数量： 1505\n",
      "过采样后训练集中类别1的数量： 1505\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.758"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(svd_topic_vectors,df.rumor,test_size=0.2 ,random_state=42)\n",
    "smote = SMOTE(random_state=42)\n",
    "# 进行过采样\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "print(\"过采样前训练集中类别0的数量：\", sum(y_train==0))\n",
    "print(\"过采样前训练集中类别1的数量：\", sum(y_train==1))\n",
    "\n",
    "print(\"过采样后训练集中类别0的数量：\", sum(y_train_res==0))\n",
    "print(\"过采样后训练集中类别1的数量：\", sum(y_train_res==1))\n",
    "lda = LDA(n_components=1)\n",
    "lda = lda.fit(X_train_res, y_train_res)\n",
    "df['LSA16_rumor'] = lda.predict(svd_topic_vectors)\n",
    "round(float(lda.score(X_test, y_test)), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rumor0!</th>\n",
       "      <th>rumor1</th>\n",
       "      <th>rumor2</th>\n",
       "      <th>rumor3</th>\n",
       "      <th>...</th>\n",
       "      <th>rumor6</th>\n",
       "      <th>rumor7!</th>\n",
       "      <th>rumor8</th>\n",
       "      <th>rumor9!</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rumor0!</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor2</th>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor3</th>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor4!</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor5</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor6</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor7!</th>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor8</th>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor9!</th>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         rumor0!  rumor1  rumor2  rumor3  ...  rumor6  rumor7!  rumor8  \\\n",
       "rumor0!      1.0     0.1    -0.1     0.1  ...     0.1      0.2    -0.1   \n",
       "rumor1       0.1     1.0    -0.1    -0.0  ...     0.0     -0.1     0.2   \n",
       "rumor2      -0.1    -0.1     1.0    -0.1  ...     0.0     -0.1    -0.0   \n",
       "rumor3       0.1    -0.0    -0.1     1.0  ...     0.0      0.1    -0.0   \n",
       "rumor4!      0.2     0.0    -0.0    -0.1  ...    -0.1      0.0    -0.1   \n",
       "rumor5       0.2     0.0    -0.0     0.0  ...    -0.1      0.1     0.1   \n",
       "rumor6       0.1     0.0     0.0     0.0  ...     1.0      0.1    -0.1   \n",
       "rumor7!      0.2    -0.1    -0.1     0.1  ...     0.1      1.0    -0.0   \n",
       "rumor8      -0.1     0.2    -0.0    -0.0  ...    -0.1     -0.0     1.0   \n",
       "rumor9!     -0.1     0.0    -0.0    -0.1  ...     0.1      0.1    -0.1   \n",
       "\n",
       "         rumor9!  \n",
       "rumor0!     -0.1  \n",
       "rumor1       0.0  \n",
       "rumor2      -0.0  \n",
       "rumor3      -0.1  \n",
       "rumor4!     -0.0  \n",
       "rumor5      -0.1  \n",
       "rumor6       0.1  \n",
       "rumor7!      0.1  \n",
       "rumor8      -0.1  \n",
       "rumor9!      1.0  \n",
       "\n",
       "[10 rows x 10 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "svd_topic_vectors = (svd_topic_vectors.T / np.linalg.norm(svd_topic_vectors,axis=1)).T\n",
    "svd_topic_vectors.iloc[:10].dot(svd_topic_vectors.iloc[:10].T).round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rumor Accuracy: 0.7877 (+/- 0.0204)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(lda, svd_topic_vectors, df.rumor, cv=5)\n",
    "print(\"rumor Accuracy: %0.4f (+/- %0.4f)\" % (scores.mean(), scores.std() * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macro: p 0.7759722714561424, r 0.8076293317675737, f1 0.7814652675478351\n",
      "micro: p 0.7938218390804598, r 0.7938218390804598, f1 0.7938218390804598\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_recall_fscore_support\n",
    "y_true = df.rumor\n",
    "y_pred = df.LSA16_rumor\n",
    "p_macro, r_macro, f_macro, support_macro \\\n",
    "    = precision_recall_fscore_support(y_true=y_true, y_pred=y_pred, labels=[0,1], average='macro')\n",
    "\n",
    "p_micro, r_micro, f_micro, support_micro\\\n",
    "    = precision_recall_fscore_support(y_true=y_true, y_pred=y_pred, labels=[0,1], average='micro')\n",
    "\n",
    "print('macro: p {}, r {}, f1 {}'.format(p_macro, r_macro, f_macro))\n",
    "\n",
    "print('micro: p {}, r {}, f1 {}'.format(p_micro, r_micro, f_micro))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   non-rumor     0.8812    0.7295    0.7982       366\n",
      "       rumor     0.6102    0.8115    0.6966       191\n",
      "\n",
      "    accuracy                         0.7576       557\n",
      "   macro avg     0.7457    0.7705    0.7474       557\n",
      "weighted avg     0.7883    0.7576    0.7634       557\n",
      "\n",
      "[[267  99]\n",
      " [ 36 155]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn import metrics\n",
    "import time\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "y_true = df.loc[y_test.index].rumor\n",
    "y_pred = df.loc[y_test.index].LSA16_rumor\n",
    "loss_total = 0\n",
    "acc = metrics.accuracy_score(y_true, y_pred)\n",
    "report = metrics.classification_report(y_true, y_pred, target_names=[\"non-rumor\",\"rumor\"], digits=4)\n",
    "confusion = metrics.confusion_matrix(y_true, y_pred)\n",
    "print(report)\n",
    "with open(\"../Chinese-Text-Classification-Pytorch/report/\"+'pca'+'.txt', 'w', encoding='utf-8') as f:\n",
    "    print(report,file=f)\n",
    "print(confusion)\n",
    "with open(\"../Chinese-Text-Classification-Pytorch/report_matrix/\"+'pca'+'_matrix'+'.txt', 'w', encoding='utf-8') as f:\n",
    "    print(confusion,file=f)\n",
    "np.savez(\"../Chinese-Text-Classification-Pytorch/report_matrix/\"+'pca'+'_matrix'+'.npz', matrix= confusion)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e6d40a5097db4c11f3975da84c5456511726d6f156896da7e31bb0c17b283947"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

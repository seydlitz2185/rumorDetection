{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据展示与预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex as re \n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集的基本信息如下：\n",
    "有1953条健康信息断言，不包含index有8列\n",
    "- 第1列“rumor”为信息的标签，二分类，0表示非谣言，1表示谣言\n",
    "- 第2列“text”为人工标注的健康信息断言，仅清洗特殊字符、使用PunctualModel补充标点\n",
    "- 第3列“seg_text”为使用哈工大停用词表去除停用词后的词表\n",
    "- 第4列“cos_matrix”为余弦相似度矩阵，按照行优先存储，每一个行向量表示该文档与其他所有文档的余弦相似度\n",
    "- 第5列“length”为“text”列的文档的长度\n",
    "- 第6列“sentiment”为情感极性得分，使用SnowNLP计算得到\n",
    "- 第7列“pca_topic_vectors”为使用sklearn中的TurncatedPCA方法计算得到的主题得分，我选择了100个维度\n",
    "- 第8列“lida_topic_vectors”使用lida得到，目前暂时是32维的主题得分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['rumor', 'text', 'seg_text', 'cos_sim', 'length', 'sentiments',\n",
       "       'pca_topic_vectors', 'ldia_topic_vectors'], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data.csv',index_col=0)\n",
    "data.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "谣言数量：913\n",
      "非谣言数量：1871\n"
     ]
    }
   ],
   "source": [
    "print(\"谣言数量：\"+str(len(data[data['rumor']==1])))\n",
    "print(\"非谣言数量：\"+str(len(data[data['rumor']==0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "全部平均长度：61.10596264367816\n",
      "谣言平均长度：16.00985761226725\n",
      "非谣言平均长度：83.11170497060395\n"
     ]
    }
   ],
   "source": [
    "print(\"全部平均长度：\"+str(sum([len(d) for d in data.text])/len(data)))\n",
    "print(\"谣言平均长度：\"+str(sum([len(d) for d in data[data['rumor']==1].text])/len(data[data['rumor']==1])))\n",
    "print(\"非谣言平均长度：\"+str(sum([len(d) for d in data[data['rumor']==0].text])/len(data[data['rumor']==0])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 首先制作一个符合Chinese-Text- Classification-Pytorch的数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集中的谣言数量:536\n",
      "测试集中的谣言数量:196\n",
      "验证集中的谣言数量:181\n"
     ]
    }
   ],
   "source": [
    "\n",
    "texts = np.array([data.index,data['seg_text'],data['rumor']]).T\n",
    "np.random.seed(2)\n",
    "np.take(texts,np.random.permutation(texts.shape[0]),axis=0,out=texts)\n",
    "train,test,dev = np.split(texts,[int(texts.shape[0]*0.6),int(texts.shape[0]*0.8)],axis=0)\n",
    "train = train.T\n",
    "test = test.T\n",
    "dev = dev.T\n",
    "print(\"训练集中的谣言数量:\"+str(sum(train[2])))\n",
    "print(\"测试集中的谣言数量:\"+str(sum(test[2])))\n",
    "print(\"验证集中的谣言数量:\"+str(sum(dev[2])))\n",
    "with open('./pygp_data/data/train.txt','w') as f:\n",
    "    for i in range(train.shape[1]):\n",
    "        f.write(str(train[0][i])+'\\t'+str(train[1][i])+'\\t'+str(train[2][i])+'\\n')\n",
    "with open('./pygp_data/data/test.txt','w') as f:\n",
    "    for i in range(test.shape[1]):\n",
    "        f.write(str(test[0][i])+'\\t'+str(test[1][i])+'\\t'+str(test[2][i])+'\\n')\n",
    "with open('./pygp_data/data/dev.txt','w') as f:\n",
    "    for i in range(dev.shape[1]):\n",
    "        f.write(str(dev[0][i])+'\\t'+str(dev[1][i])+'\\t'+str(dev[2][i])+'\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e6d40a5097db4c11f3975da84c5456511726d6f156896da7e31bb0c17b283947"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
